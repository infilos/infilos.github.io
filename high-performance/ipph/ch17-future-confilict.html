<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>CH17-未来的冲突 · Infilos</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content='Infilos'/>
<link href="https://fonts.googleapis.com/css?family=Roboto:100normal,100italic,300normal,300italic,400normal,400italic,500normal,500italic,700normal,700italic,900normal,900italicc" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../../js/page.js"></script>
<script type="text/javascript" src="../../js/warnOldVersion.js"></script>
<script type="text/javascript" src="../../js/groups.js"></script>
<link rel="stylesheet" type="text/css" href="../../lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="../../lib/foundation/dist/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="../../css/page.css"/>

<!--
<link rel="shortcut icon" href="../../images/favicon.ico" />
-->
</head>

<body>
<div class="off-canvas-wrapper">
<div class="off-canvas-wrapper-inner" data-off-canvas-wrapper>

<div class="off-canvas position-left" id="off-canvas-menu" data-off-canvas>
<nav class="off-canvas-nav">
<div class="nav-home">
<a href="../../index.html" >
<span class="home-icon">⌂</span>Infilos
</a>
<div class="version-number">
1.0
</div>
</div>
<div class="nav-toc">
<ul>
  <li><a href="../../java-lang/index.html" class="page">Java Lang</a>
  <ul>
    <li><a href="../../java-lang/basics/index.html" class="page">Basics</a></li>
    <li><a href="../../java-lang/effects/index.html" class="page">Effectives</a></li>
    <li><a href="../../java-lang/profess/index.html" class="page">Professionals</a></li>
    <li><a href="../../java-lang/puzzles/index.html" class="page">Puzzles</a></li>
  </ul></li>
  <li><a href="../../java-concur/index.html" class="page">Java Concurrency</a>
  <ul>
    <li><a href="../../java-concur/puzzles/index.html" class="page">Puzzles</a></li>
  </ul></li>
  <li><a href="../../scala-lang/index.html" class="page">Scala Lang</a>
  <ul>
    <li><a href="../../scala-lang/basics/index.html" class="page">Basics</a></li>
    <li><a href="../../scala-lang/effects/index.html" class="page">Effectives</a></li>
    <li><a href="../../scala-lang/profess/index.html" class="page">Professionals</a></li>
    <li><a href="../../scala-lang/puzzles/index.html" class="page">Puzzles</a></li>
  </ul></li>
  <li><a href="../../scala-concur/index.html" class="page">Scala Concurrency</a></li>
  <li><a href="../../monitoring-tracing/index.html" class="page">Monitoring &amp; Tracing</a>
  <ul>
    <li><a href="../../monitoring-tracing/google-dapper-essentials.html" class="page">Google Dapper</a></li>
    <li><a href="../../monitoring-tracing/opentracing-spec.html" class="page">OpenTracing</a></li>
    <li><a href="../../monitoring-tracing/zipkin/index.html" class="page">Zipkin</a></li>
    <li><a href="../../monitoring-tracing/pinpoint.html" class="page">Pinpoint</a></li>
  </ul></li>
  <li><a href="../../high-performance/index.html" class="page">High Performance</a>
  <ul>
    <li><a href="../../high-performance/ipph/index.html" class="page">Parallel Programming</a></li>
    <li><a href="../../high-performance/seven-model/index.html" class="page">Seven Models</a></li>
    <li><a href="../../high-performance/java-thread-model/index.html" class="page">Java Thread Model</a></li>
  </ul></li>
</ul>
</div>

</nav>
</div>

<div class="off-canvas-content" data-off-canvas-content>

<header class="site-header expanded row">
<div class="small-12 column">
<a href="#" class="off-canvas-toggle hide-for-medium" data-toggle="off-canvas-menu"><svg class="svg-icon svg-icon-menu" version="1.1" id="Menu" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 20 20" enable-background="new 0 0 20 20" xml:space="preserve"> <path class="svg-icon-menu-path" fill="#53CDEC" d="M16.4,9H3.6C3.048,9,3,9.447,3,10c0,0.553,0.048,1,0.6,1H16.4c0.552,0,0.6-0.447,0.6-1C17,9.447,16.952,9,16.4,9z M16.4,13
H3.6C3.048,13,3,13.447,3,14c0,0.553,0.048,1,0.6,1H16.4c0.552,0,0.6-0.447,0.6-1C17,13.447,16.952,13,16.4,13z M3.6,7H16.4
C16.952,7,17,6.553,17,6c0-0.553-0.048-1-0.6-1H3.6C3.048,5,3,5.447,3,6C3,6.553,3.048,7,3.6,7z"/></svg>
</a>
<div class="title"><a href="../../index.html">Infilos</a></div>

<!--
<a href="https://www.example.com" class="logo show-for-medium">logo</a>
-->
</div>
</header>

<div class="expanded row">

<div class="medium-3 large-2 show-for-medium column">
<nav class="site-nav">
<div class="nav-home">
<a href="../../index.html" >
<span class="home-icon">⌂</span>Infilos
</a>
<div class="version-number">
1.0
</div>
</div>
<div class="nav-toc">
<ul>
  <li><a href="../../java-lang/index.html" class="page">Java Lang</a>
  <ul>
    <li><a href="../../java-lang/basics/index.html" class="page">Basics</a></li>
    <li><a href="../../java-lang/effects/index.html" class="page">Effectives</a></li>
    <li><a href="../../java-lang/profess/index.html" class="page">Professionals</a></li>
    <li><a href="../../java-lang/puzzles/index.html" class="page">Puzzles</a></li>
  </ul></li>
  <li><a href="../../java-concur/index.html" class="page">Java Concurrency</a>
  <ul>
    <li><a href="../../java-concur/puzzles/index.html" class="page">Puzzles</a></li>
  </ul></li>
  <li><a href="../../scala-lang/index.html" class="page">Scala Lang</a>
  <ul>
    <li><a href="../../scala-lang/basics/index.html" class="page">Basics</a></li>
    <li><a href="../../scala-lang/effects/index.html" class="page">Effectives</a></li>
    <li><a href="../../scala-lang/profess/index.html" class="page">Professionals</a></li>
    <li><a href="../../scala-lang/puzzles/index.html" class="page">Puzzles</a></li>
  </ul></li>
  <li><a href="../../scala-concur/index.html" class="page">Scala Concurrency</a></li>
  <li><a href="../../monitoring-tracing/index.html" class="page">Monitoring &amp; Tracing</a>
  <ul>
    <li><a href="../../monitoring-tracing/google-dapper-essentials.html" class="page">Google Dapper</a></li>
    <li><a href="../../monitoring-tracing/opentracing-spec.html" class="page">OpenTracing</a></li>
    <li><a href="../../monitoring-tracing/zipkin/index.html" class="page">Zipkin</a></li>
    <li><a href="../../monitoring-tracing/pinpoint.html" class="page">Pinpoint</a></li>
  </ul></li>
  <li><a href="../../high-performance/index.html" class="page">High Performance</a>
  <ul>
    <li><a href="../../high-performance/ipph/index.html" class="page">Parallel Programming</a></li>
    <li><a href="../../high-performance/seven-model/index.html" class="page">Seven Models</a></li>
    <li><a href="../../high-performance/java-thread-model/index.html" class="page">Java Thread Model</a></li>
  </ul></li>
</ul>
</div>

</nav>
</div>

<div class="small-12 medium-9 large-10 column">
<section class="site-content">

<span id="version-warning"></span>

<div class="page-header row">
<div class="medium-12 show-for-medium column">
<div class="nav-breadcrumbs">
<ul>
  <li><a href="../../index.html">Infilos</a></li>
  <li><a href="../../high-performance/index.html">High Performance</a></li>
  <li><a href="../../high-performance/ipph/index.html">Parallel Programming</a></li>
  <li>CH17-未来的冲突</li>
</ul>
</div>
</div>
</div>

<div class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#ch17-未来的冲突" name="ch17-未来的冲突" class="anchor"><span class="anchor-link"></span></a>CH17-未来的冲突</h1>
<p>本章将描述并行编程在将来可能出现的，一些可能互相冲突的技术。不过我们不清楚到底哪些冲突的技术可能会真的出现，实际上，任何一个都不确定是否会出现。但他们仍然很重要，因为每一种可能出现的技术都有其拥护者。并且，如果足够多的人强烈相信某个事情，你就不得不在他的阴影下生活，还要考虑他给他的拥趸们带来的思想、言语和行为的影响。除此之外，这些技术中的一个或多个完全可能会真的出现。当然，在这些技术中，大多数都不会出现。理清这些关系对自身的认识也有好处。</p>
<p>因此，一下章节我们将介绍内存事务、硬件事务、并行函数式编程。</p>
<h2><a href="#曾经的-cpu-技术不代表未来" name="曾经的-cpu-技术不代表未来" class="anchor"><span class="anchor-link"></span></a>曾经的 CPU 技术不代表未来</h2>
<p>根据多年的经验，回首过去的岁月总是那么简单和无知。21世纪初，最大的无知表现为：摩尔定律开始慢慢失效，该定律认为可以持续增加 CPU 的时钟频率。以前，也偶尔有一些技术限制方面的警告，但是这些警告已经出现了数十年。请注意考虑下面的场景。</p>
<ol>
  <li>单处理器 Uber Alles(图 17.1)。</li>
  <li>多线程 Mania(图 17.2)。</li>
  <li>更多类似的(图 17.3)。</li>
</ol>
<h3><a href="#单处理器-uber-alles" name="单处理器-uber-alles" class="anchor"><span class="anchor-link"></span></a>单处理器 Uber Alles</h3>
<p>正如 2004 年的文献所说：</p>
<p>在这个场景里，通过将摩尔定律在 CPU 时钟频率方面的增长，以及持续的水平扩展计算进行组合，将使得 SMP 系统变得无关紧要。这种场景被称为“单处理器 Uber Alles”，字面上的意思就是“单处理器高于一切”。</p>
<p>这些单处理器只会受指令开销的限制，因为内存屏障、缓存抖动以及缓存竞争，这些都不会在单处理器上产生影响。在这个场景里，RCU 只会用于一些特殊应用，如与 NMI 交互。不清楚一些没有实现 RCU 的操作系统是否需要引入 RCU，尽管一些实现了 RCU 的操作系统会继续使用它。</p>
<p>但是，最近多线程处理器的发展显示该场景不会太快出现。</p>
<p>确实不太可能！但是大型软件社区不太愿意接受这样的事实：他们需要拥抱并行，在社区得到如下结论前，还需要一些时日，摩尔定律提升 CPU 频率的这个免费午餐真的已经结束了。不要忘记，信念是一种感情，而不是理性技术思考的结果。</p>
<h3><a href="#多线程-mania" name="多线程-mania" class="anchor"><span class="anchor-link"></span></a>多线程 Mania</h3>
<p>下面这段话来自 2004 年的文献：</p>
<p>有一种不太极端的 Uber Alles 变种，它仍然是一个单处理器，但是具有硬件多线程。最激进的多线程 CPU，会共享所有级别的缓存，因而消除了 CPU 间的内存延迟，相应的，也大大减少了传统同步机制的性能消耗。但是，多线程 CPU 仍然会遭受由于内存平杭州哪个引起的竞争和流水线停顿。另外，由于所有的硬件线程共享所有级别的缓存，可用于单个硬件线程的缓存资源，只是等效单线程 CPU 上高速缓存的一笑部分，这就会降低那些大量使用缓存的程序性能。由于 RCU 优雅周期会产生额外的内存消耗，所以也存在一定的可能性，有限的缓存也会使得基于 RCU 的算法招致心梗损失。调查这种可能性是未来的工作。</p>
<p>但是，为了避免这样的性能损失，一些多线程 CPU 和多 CPU 芯片会基于每硬件线程，至少将某些级别的缓存进行分区。这样，对于每个硬件线程来说，增加了它们的可用缓存数量，但是也重新引入了硬件线程间传递的内存行延迟。</p>
<p>最终，我们都知道这个问题是怎么产生的，那就是将位于单个模具上的多个线程核放到单个 socket 中。这样，问题就编程未来的基于共享内存的是否是否将一直放到单个 socket 中。</p>
<h3><a href="#更多类似场景" name="更多类似场景" class="anchor"><span class="anchor-link"></span></a>更多类似场景</h3>
<p>下面这段话来自 2004 年的文献：</p>
<p>更多类似的场景假设，内存延迟比率仍然会保持如今的现状。</p>
<p>这种情况实际上表示有了一些变化，因为有更多相同的说法。内部互联性能必须赶得上随摩尔定律对 CPU 性能的提升。在这种场景下，流水线阻塞、内存延迟以及竞争带来的开销仍然很突出，RCU 仍然像目前一样保持了其高水平的可用性。</p>
<p>这种变化仍然是摩尔定律在提供的，不断提升的集成度。但是从长期来看，到底是哪个？是每个模具上放置更多的 CPU？还是更多的 IO、缓存、内存？</p>
<p>服务器似乎选择的是前者，而片上嵌入式系统(SoCs)继续选择后者。</p>
<h3><a href="#撞上内存墙" name="撞上内存墙" class="anchor"><span class="anchor-link"></span></a>撞上内存墙</h3>
<p>下面这段话来自 2004 年的文献：</p>
<p>如图 17.5 中所示，如果内存延迟趋势继续持续下去，相对于指令延迟来说，内存延迟的开销将会继续增加。一些像 Linux 这样大量使用 RCU 的系统，将是有利可图的，如图 17.6。如果 RCU 被大量使用，则随着内存延迟比率的增加，将显示出 RCU 比其他同步机制更有优势。相反，较少使用 RCU 的系统，会大大增加读的负担，这些负担原本由对 RCU 的使用而减少，如图 17.7。正如图中所示，如果 RCU 用的不多，随着内存延迟比率增加，与其他同步机制，RCU 会处于越来越有利的地位。由于 Linux 在高负载下，每个优雅周期有超过 1600 个回调，因此我们可以说 Linux 属于前者。</p>
<div  align="center">
<img src="https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180922204547.png" style="display:block;width:50%;" alt="NAME" align=center />
</div>
<div  align="center">
<img src="
https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180922204607.png" style="display:block;width:50%;" alt="NAME" align=center />
</div>
<div  align="center">
<img src="https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180922204622.png" style="display:block;width:50%;" alt="NAME" align=center />
</div>
<p>一方面，这段文字并没有预见到缓存热度的问题，而 RCU 可以承受大量高强度更新写负载的情况，大概是因为 RCU 看起来不大可能会用于这种情况。如果，如顺序锁一样，SLAB_DESTROY_BY_RCU 已经作为一种服务，用在一些存在缓存热点问题的地方。从另一方面来说，我们也没有预见到 RCU 用来降低调度延迟或者安全相关的问题。</p>
<p>简而言之，还是要小心进行预测，包括本章后面要讨论的部分。</p>
<h2><a href="#事务内存" name="事务内存" class="anchor"><span class="anchor-link"></span></a>事务内存</h2>
<p>在数据库以外的领域，使用事务的想法在数十年前就存在了，数据库和非数据库事务的关键不同点在于，非数据库事务在定义事务的 ACID 属性中去除了 D。近年来主流认为，基于内存的事务方法，即所谓的“内存事务(TM)”，应更多倾向于由硬件来实现。不幸的是，支持事务的商业硬件不会立即出现，尽管其他一些类似的计划已经提出。不久前，Shavit 和 Touitou 提出一个纯软件的事务内存实现(STM)，它能够运行在商业硬件上，或多或少的解决内存序的问题。该提议被束之高阁多年，也许是因为研究团体的注意力更专注于非阻塞式同步。</p>
<p>但是到了世纪之交，TM 开始受到更多关注，到了 2005 年左右已经到了白热化的程度，尽管还是有一些质疑的声音存在。</p>
<p>隐含于 TM 的基本思想是，原子的执行一个代码段，这样其他线程将不会看到任何中间状态。同样的，TM 的语义能够通过以重复的获得、释放全局锁来替换每一个事务来简单的实现，尽管存在糟糕的性能和扩展性问题。大部分 TM 实现中的复杂性(不管是软件实现还是硬件实现)，都是有效的检测并发事务何时能安全的并发运行。由于这类检测是动态进行的，冲突的事务能够被中止或回退。并且在某些实现中，异常模式对开发者是可见的。</p>
<p>随着事务长度的减小，事务回退越来越不大可能出现，所以 TM 对小的、基于内存的操作是很有吸引力的。例如用于栈管理的链表维护、对了、哈希表、搜索树。无论如何，对于大事务来说，当前还是更难于处理，特别是一些包含 IO 操作及进程创建这样的非内存操作的事务。以下章节将讨论“事务内存无处不在”这个宏达远景在当前遇到的挑战。</p>
<h3><a href="#外部世界" name="外部世界" class="anchor"><span class="anchor-link"></span></a>外部世界</h3>
<p>Donald Knuth 说：</p>
<p>许多计算机用户觉得，输入和输出实际上不是“纯粹编程”的一部分，它们仅仅是(不幸的)机器为了输入输出信息所必须要做的事情。</p>
<p>不管我们是否相信输入输出是“纯粹编程”，事实上对于绝大多数计算机系统来说，与外部世界交互是第一级的需求。因此本节对事务内存在这些交互方面的能力进行批评，不管这些交互是 IO 操作，还是时间延迟或者持久存储。</p>
<h4><a href="#io-操作" name="io-操作" class="anchor"><span class="anchor-link"></span></a>IO 操作</h4>
<p>用户能够在基于锁(原理上讲，至少可以在临界区读锁内)的临界区执行 IO 操作。当你在一个事务中尝试执行一个 IO 操作时，将会发生什么？</p>
<p>潜在的问题是事务可能会回退，例如，当发生事务冲突时。总的来说，被要求在任何特定事务中的所有操作都是可以撤销的，这样，两次与一次执行操作的效果是相同的。不幸的是，IO 通常是不可撤销的操作，这使得用户很难在事务中执行 IO 操作。事实上，IO 操作通常是不可撤销的，一旦你按下了发射核弹的按钮，就没有回头路可走。</p>
<p>以下是在事务中处理 IO 操作的可选方法。</p>
<ol>
  <li>在事务中，限制 IO 为位于内存缓冲区的缓冲 IO。这样，这些缓冲区可以像事务中的其他内存单元一样，以相同的方式将其包含到事务中。这似乎是一个可选的机制，并且可以在绝大多数的通常情况下正常运行，例如流 IO 或者大容量存储 IO。但是，当来自于多个进程的多个输出流合并到一个单个的文件时，需要特殊处理。例如使用“a+”选项调用 fopen 或者 O_APPEND 标志调用 open 所做的。另外，正如在下一节将看到的一样，网络操作通常不能通过缓冲区来处理。</li>
  <li>在事务中禁止 IO，任何 IO 操作都会中止所属事务(也许是多个嵌套事务)。这种方案似乎是用于处理非缓存 IO 的常规 TM 方法，但需要与其他允许 IO 操作同步原语配合使用。</li>
  <li>在事务中禁止 IO，但是需要编译器的帮助以强制禁止这种行为。</li>
  <li>在任意时刻，仅允许一个“不可撤销”事务运行，这样，就可以在“不可撤销”事务里包含 IO 操作。在通常情况下这种方案是可行的，但是严重限制了 IO 操作的性能和扩展性。而扩展性和性能是并行编程的首要目的。更糟糕的是，允许 IO 操作的不可撤销能力，这种用法看来禁止了手动中止事件这种用法。最后，如果有一个维护数据项的不可撤销事务，那么其他维护相同数据项的其他事务将不能有非阻塞语义。</li>
  <li>创建新的硬件和协议，其 IO 操作能够被放入事务底层。在输入操作时，硬件需要正确的预测操作结果，如果预测失败就中止事务。</li>
</ol>
<p>IO 操作的支持是 TM 公认的弱点，目前还不清楚，在事务中支持 IO 是否有一个合理的通用方案。至少，合理的要求是具有良好的性能和可扩展。至少，合理的要求是具有良好的性能和扩展性。不过，对于这个问题给与持续的时间及关注度，将很有可能产生额外的进展。</p>
<h4><a href="#rpc-操作" name="rpc-操作" class="anchor"><span class="anchor-link"></span></a>RPC 操作</h4>
<p>用户能够在一个基于锁的临界区(如 RCU 的读端临界区)执行 RPC。尝试在一个事务中执行一个 RPC 会发生什么呢？</p>
<p>如果 RPC 请求和它的响应被包含在同一个事务中，并且事务的某些部分依赖于响应的结果，那么就不可能使用在缓冲 IO 时用到的内存缓冲区这种技巧。任何尝试使用这种缓冲方法的努力都会导致事务产生死锁。直到事务完成前，RPC 请求才能发送，但是直到接收到请求前，事务不能成功，对于这种情况，有如下例子：</p>
<pre class="prettyprint"><code class="language-c">1 begin_trans(); 
2 rpc_request(); 
3 i = rpc_response(); 
4 a[i]++; 
5 end_trans();
</code></pre>
<p>直到接收到 RPC 请求的响应后，事务的内存印记才能被确定下来；直到请求的内存印记被确定后，才能确定是否允许提交事务。</p>
<p>以下是 TM 可用的选项：</p>
<ol>
  <li>在事务中禁止 RPC，这样，视图执行一个 RPC 操作将中止所属的事务(也许是多个嵌套的事务)。可选的，可以借助编译器的帮助强制禁止 RPC。这种方式能够工作，但是需要 TM 与其他同步原语配合。</li>
  <li>在任何特定时刻，仅仅允许有一个特定的“不可撤销”事务在执行，这样就允许“不可撤销”事务包含 RCP 操作。通常情况下这是可行的，但是严重限制了 RPC 操作的可扩展性和性能，而扩展性和性能是并行编程的首要目标。这种方法看起来有点自我限制。而且，使用“不可撤销”事务以容许 RCP 操作，这就不允许在 RPC 操作开始后手动中止事务。最后，如果有一个维护特定数据项的不可撤销事务，那么任何维护同一数据项的其他事务，就不能拥有非阻塞语义。</li>
  <li>识别特殊情况，在接收 RPC 响应之前，可以确认事务成功。并且在发送 RPC 之前将其转换为不可撤销的事务。当然，如果几个并发事务尝试调用 RPC，则可能需要回退所有事务，仅仅保留一个事务。这必然降低性能和可扩展性。然而，这种方法对长 的、以 RPC 结束的事务是有价值的。这种方法对手动中止事务来说也是存在问题的。</li>
  <li>识别特殊情况，RPC 响应可以被移到事务之外。那么就用类似于使用缓冲 IO 的方式进行处理。</li>
  <li>扩展事务底层，使得 RPC 服务器端和客户端都被包含在事务内部。从理论上讲这是可行的，并且已经被分布式数据库证明。但是，尚不能确定借助分布式数据库技术是否能满足性能和扩展性，因为基于内存的 TM 不能解决慢速磁盘设备的延迟问题。当然，考虑到固态磁盘的出现，也不清楚多大的数据库才能解决掉隐藏在这些磁盘驱动之中的延迟。</li>
</ol>
<p>正如前一节提到的，IO 是 TM 的一个有名的缺点，RPC 是其中一个特别突出的问题。</p>
<h4><a href="#延时" name="延时" class="anchor"><span class="anchor-link"></span></a>延时</h4>
<p>与实务外部进行交互的一种重要的特殊情况包括，在事务内部的显式延迟操作。当然，在事务中进行延迟的想法与 TM 的原子性向抵触，但人们可以辩解，这不过是弱原子性的一种表现而已。而且，为了正确进行基于内存映射的 IO 交互，有时需要小心控制延迟，并且应用程序常常因为不同的目的执行延迟操作。</p>
<p>关于在事务中进行延迟的问题，TM 能做些什么呢？</p>
<ol>
  <li>在事务中忽略延迟。这看起来不错，但是像其他“好”方法一样，可能不会兼容一些老的代码。这些老代码，可能子临界区中需要重要的延迟，将其事务化时将会失败。</li>
  <li>遇到延时操作时，中止事务。这是比较吸引人的方法，但是不幸的是，并不是总能自动检测到延迟操作。一些重要的延时计算是紧凑循环操作，或者是等待一段时间的消逝。</li>
  <li>让编译器来禁止事务中的延时操作。</li>
  <li>让延时操作正常运行。不幸的是，一些 TM 仅仅在发布时才提交修改，很多情况下会失去延时的目的。</li>
</ol>
<p>不清楚是否只有唯一的正确答案。弱原子性的 TM 实现，会在事务内存立即发布更改(在中止后回退这些更改)，它可能由最后一种方法来合理实现。即使在这种情况下，事务另一端中的代码可能需要大量重新设计，以允许中止事务。</p>
<h4><a href="#持久性" name="持久性" class="anchor"><span class="anchor-link"></span></a>持久性</h4>
<p>存在很多类型的原语。一个有趣的特性是持久性。换句话说，离开了锁持有者的进程空间，这把锁是否能够独立存在。</p>
<p>非持久性锁包括 pthread_mutex_lock、pthread_rwlock_rdlock，以及大多数内核级别的锁原语。如果实例化一个非持久性锁的数据结果消失，锁不复存在。对于典型的pthread_mutex_lock 用法，这意味着当前进程退出时，它的所有锁将消失。为了在程序退出时自动进行琐碎的锁清理操作，可以利用该特性。但是不同进程共享锁使得这件事情变得更加困难。因为这样的共享需要在应用间共享内存。</p>
<p>持久性锁有助于避免在无关应用之间共享内存。持久性锁 API 包括 flock 系列、lockf、System V 信号量，以及 O_CREAT 标志的 open 调用。这些持久性 API 能够在大范围内操作，这些操作分布于多个应用之间。并且，在 O_CREAT 这种情况下，甚至能在操作系统重启后有效。如果有必要，通过分布式锁管理，锁还能够跨越多计算机系统。</p>
<p>持久性锁能够用于任何应用，包括使用不同语言及开发环境编写的应用。实际上，一个持久性锁可以被一个 C 语言编写的应用获得，然后被一个以 Python 编写的应用释放。</p>
<p>TM 如何提供类似的持久性功能？</p>
<ol>
  <li>将持久性事务限定在特定目的的环境中，这些环境被设计用于支持它们。如 SQL。这明显可以工作，因为数据库系统对此的支持已经有数十年的历史了，但是不提供持久性锁一样级别的灵活性。</li>
  <li>使用由一些存储设备和文件系统提供的快照功能。不幸的是它不能处理网络通信，在不能提供快照能力的设备(如内存记忆棒)上，也不能处理其他 IO。</li>
  <li>构建某种时间机器。</li>
</ol>
<p>当然，事务内存这个称呼应该暂停，这个名称与持久性事务的概念是冲突的。尽管如此，还是值得考虑这种可能性，将它作为一个重要的测试案例，以探测事务内存的固有限制。</p>
<h3><a href="#进程修改" name="进程修改" class="anchor"><span class="anchor-link"></span></a>进程修改</h3>
<p>进程不是永久存在的，它们被创建于销毁，它们的内存映射被修改，它们会链接动态链接库，并且它们可以被调试。这几节关注事务内存如何处理变化的执行环境。</p>
<h4><a href="#多线程事务" name="多线程事务" class="anchor"><span class="anchor-link"></span></a>多线程事务</h4>
<p>当进程或线程在持有一个锁，或者处于 RCU 读端临界区的时候，创建进程或线程是完全合法的。这不仅合法，而且非常简单，如下代码所示。</p>
<pre class="prettyprint"><code class="language-c">1 pthread_mutex_lock(...); 
2 for (i = 0; i &lt; ncpus; i++) 
3 pthread_create(&amp;tid[i], ...); 
4 for (i = 0; i &lt; ncpus; i++) 
5 pthread_join(tid[i], ...); 
6 pthread_mutex_unlock(...);
</code></pre>
<p>这段伪代码使用 pthread_create 为每一个 CPU 创建一个线程，然后使用 pthread_join 等待每个线程结束运行。整个过程处于 pthread_mutex_lock 保护之下。效果就是可以并行执行基于锁的临界区。也可以使用 fork 和 wait 获得类似的效果。当然，临界区通常需求十分大，以抵消生成进程的开销，但是在产品中确实存在大临界区的例子。</p>
<p>在事务中进行线程创建，TM 能做什么呢？</p>
<ol>
  <li>在事务中执行 pthread_creat，将这种行为定义为非法的，这将导致事务被中止(这样更好)或者产生不可预计的后果。相应的，借助编译器确保在事务中不进行 pthread_create。</li>
  <li>允许在事务中执行 pthread_create，但是仅仅允许将父线程作为事务的一部分。这种方法看起来与已有的、或者假想的 TM 实现相当一致。但是稍不留意就会掉进坑里。这种方法带来了更多的问题，比如如何处理子线程访问的冲突。</li>
  <li>将 pthread_create 转换成函数调用。这个方法是个美丽的陷阱。他不能处理一些其实并不罕见的情况，如子线程与另外的线程通信。另外，这个方法不允许事务体并行执行。</li>
  <li>扩展事务以包含福线程和它的子线程。该方法带来的访问冲突本质方面的、有意思的问题。因为父线程和子线程之间允许互相冲突，但是却不允许与其他线程冲突。还会带来一些其他问题，在提交事务前，如果父线程不等待子线程将会发生什么？更有意思的问题是，如果父进程根据事务中的变量值作为判断条件，决定是否调用 pthread_join，那么将发生什么？这些问题的答案在基于锁的情况下是显而易见的，那 TM 的解决方案就留给读者作为练习。</li>
</ol>
<p>在数据库领域中，事务的并行执行是相当常见的。奇怪的是，当前的 TM 方案并不提供此功能。另一方面，上面的例子是非常复杂的锁用法，这在一般的教科书里找不到，所以也许可以预期它将被忽略。房间传闻说，一些 TM 研究者在琢磨把 fork 和 join 并行化做到事务里，也许本节的问题很快就会被解决。</p>
<h4><a href="#exec-系统调用" name="exec-系统调用" class="anchor"><span class="anchor-link"></span></a>exec 系统调用</h4>
<p>在持有锁时能够执行 exec 系统调用，也能在持有 RCU 读锁时执行。确切的语义视原类型而定。</p>
<p>在非持久性原语下(包括 pthread_mutex_lock、pthread_rwlock_rdlock、RCU)，如果 exec 成功了，整个地址空间就消失了，并且是持有锁的情况下地址空间消失了。当然，如果 exec 执行失败，地址空间仍然存在，因此相关的锁也存在。也许有点奇怪，但是其含义相当明确。</p>
<p>另一方面，不管 exec 是否成功，持久性原语(包括 flock 系列、lockf、System V 信号量、带 O_CREAT 标志的 open 调用)都将能持续下来，执行过 exec 的程序能够方便释放他们。</p>
<p>当你在事务中执行一个 exec 系统调用会发生什么？</p>
<ol>
  <li>不允许在事务中包含 exec，因此在封闭事务中执行 exec 将中止事务。这通常行得通，不过显然要求非 TM 同于原语与 exec 结合使用。</li>
  <li>不允许在事务中包含 exec，这是由编译器强制禁止的。有一个针对 TM 的 C++标准草案，采用了这种方案。这允许使用 transcation_safe 和 transcation_unsafe 属性来标示函数。与在运行时中止事务相比，这个方法有一定优势，但是仍然要求非 TM 的同步原语与 exec 结合使用。</li>
  <li>以类似非持久性锁原语的方式来处理事务，这样在 exec 失败的时候，事务还会侥幸运行。如果 exec 成功，则事务暗地里被提交。如果某些变量受到事务影响，而这些变量位于 mmap 映射区域(因此在成功的 exec 系统调用之后仍然存在)，这种情况留给读者作为练习。</li>
  <li>当 exec 系统调用已经完成时，终止事务(和 exec 系统调用)。但是当 exec 失败时，则继续运行事务。这看起来是正确的做法，但是需要做的工作比较多，并且还不一定有好的效果。</li>
</ol>
<p>exec 系统调用，也许是一个关于 TM 适用性障碍方面最奇怪的例子。到底采用哪种解决方法才合理，目前还不是完全清楚。有些人认为，这不过是真实场景里与 exec 族进行交互的风险体现。在事务中禁止 exec，这两个选项也许是最合乎逻辑的。</p>
<p>类似的问题也存在于 exit 和 kill 系统调用上面。</p>
<h4><a href="#动态链接装载" name="动态链接装载" class="anchor"><span class="anchor-link"></span></a>动态链接装载</h4>
<p>基于锁的临界区以及 RCU 读保护的临界区，都可以合法的包含调用动态链接装载的代码，包括 C/C++ 共享库和 Java 类库。当然，包含在这些库中的代码在编译时是未知的。因此，如果在事务中调用动态加载的函数将会发生什么？</p>
<p>该问题包含两个部分：(1)在事务中如何动态链接并转载函数；(2)面对在事务中包含位置代码这个特性，你该做什么？公平的说，2 所包含的挑战在锁和 RCU 中也存在，至少理论上存在。例如，动态链接函数可能导致死锁，或者在 RCU 读保护的情况下，引入一次静止状态。不同之处在于，在锁保护及 RCU 保护的临界段中，合法的操作集是容易理解的，但是在 RM 里就没有明确的合法操作集合了。实际上，不同的 TM 实现由不同的限制。</p>
<p>在动态链接装载库函数方面，TM 能做些什么呢？对第一个问题来说，包含以下可选项：</p>
<ol>
  <li>以类似于缺页异常的方式，对待动态链接和装载。这样，函数被链接装载，在此过程中可能中止事务。如果事务被中止了，重试事务时，将会发现函数已经存在，因此预期事务能够正常处理。</li>
  <li>在事务内不允许动态链接加载函数。</li>
</ol>
<p>对第二个问题来说，不能检测尚未装载库函数中的 TM 不友好的操作，可能的选项包括以下几个方面。</p>
<ol>
  <li>执行相应的代码，如果有任何 TM 不友好的操作，则简单终止事务。不幸的是，该方法使得编译器无法检测一组特定的事务是否可以安全的组合在一起。一个方式是总是允许将事务组合在一起，而不考虑是否为不可撤销事务。但是，当前的实现仅仅允许在一个指定时间处理一个不可撤销的事务，这将极大的限制性能和扩展性。不可撤销事务的使用，看起来也禁止了手动中止事务操作。最后，如果一个不可撤销事务维护一个特定数据项，其他维护同一个数据项的事务不能执行非阻塞语义。</li>
  <li>通过函数修饰符标示函数是 TM 友好的。这可以由编译器的类型系统来强制标示。当然，对很多语言来说，这需要对语言进行扩展，标准化以及实现，并且需要一定时间。据说，标准化工作已经在进行中了。</li>
  <li>和前面一样，也可以采取在 TM 里禁止动态链接加载函数的方案。</li>
</ol>
<p>IO 操作当然是 TM 的一个众所周知的弱点，动态链接装载也可以看做是另外一种 IO 特例。然而，TM 提倡者必须要么解决这个问题，要么认命，仅仅将 TM 作为并行编程工具箱中一个普通工具。</p>
<h4><a href="#内存映射操作" name="内存映射操作" class="anchor"><span class="anchor-link"></span></a>内存映射操作</h4>
<p>在一个基于锁的临界区内(至少从原理上讲，包含 RCU 读端临界区)执行内存映射操作(包括 mmap、shmat、munmap)是完全合法的。当你在一个事务中执行这样的操作会发生什么？更进一步说，重新映射包含了当前线程事务变量的区域会发生什么？并且，如果内存区域包含其他线程事务的变量时又会发生什么？</p>
<p>不用特别考虑 TM 系统元数据被重新映射的情况，因为大多数加解锁原语并没有定义重映射锁变量的结果。</p>
<p>以下是对于 TM 来说，内存映射的可用选项：</p>
<ol>
  <li>在一个事务中进行内存映射是不合法的，将会导致所属事务被中止。这虽然在一定程度上简化了设计，但仍然需要 TM 与支持重映射的同步原语配合使用。</li>
  <li>在一个事务中进行内存映射是不合法的，借助编译协助确保这个限制。</li>
  <li>在一个事务内存中进行内存重新映射是合法的，但是那些在受影响区域范围内存在事务变量的其他事务，将被中止。</li>
  <li>在一个事务中进行内存映射是合法的，但是如果映射区域与当前事务内存印记有重叠，则映射将失败。</li>
  <li>所有内存映射的操作，不管是否处于一个事务内，都将检查相应的区域是否与系统内其他事务的内存印记重叠。如果重叠，则内存映射将失败。</li>
  <li>TM 冲突管理机制将检查内存映射对所有事务内存印记重叠的影响，它可以动态的确定是否让内存映射失败，还是让冲突的事务中止。</li>
</ol>
<p>要注意 munmap 删除了内存映射，将会带来很多问题。</p>
<h4><a href="#调试" name="调试" class="anchor"><span class="anchor-link"></span></a>调试</h4>
<p>通常的调试工作(如断点)可以在基于锁及 RCU 读锁这样的临界区中正常工作。但是，在早期的事务内存硬件中执行一个异常将会中止事务，这意味着断点将中止所属事务。</p>
<p>那么如何调试事务呢？</p>
<ol>
  <li>在包含断点的事务中使用软件模拟技术。当然，任意时刻，在事务内部任意一处设置断点，都应该模拟所有的事务，这也许是重要的。如果运行时系统不能确认给定的一个断点是否位于事务内，则为了安全起见需要模拟所有的事务。但是，这种方法可能带来过大的开销，从而掩盖正在跟踪的 BUG。</li>
  <li>仅仅使用能够处理断点异常的硬件 TM 实现。不幸的是，截止 2008 年 9 月，所有这样的实现仅仅是研究原型。</li>
  <li>仅仅使用软件 TM 实现，这比更简单的硬件 TM 实现更能容忍异常，当然，软件 TM 往往比硬件 TM 的消耗更高，因此在所有情形下，该刚方法可能不会被接受。</li>
  <li>更小心的编程，这样从一开始就避免在事务中产生 BUG。一旦你已经清楚如何做到这一点，请让所有人都知道这个秘密。</li>
</ol>
<p>有些理由让人相信事务内存将比其他同步机制更能提高生产力，但是如果传统的调试技术不能应用到事务上的话，看来就很有可能导致这种对生产力的提高被抵消。特别是新手在编写大的事务时，更是如此。相对的，类似于“当家花旦”这样的程序员也许不需要这些调试帮助，特别是小的事务。</p>
<p>因此，如果事务内存是为了提高新手程序员的生产效率，那么调试问题就需要解决。</p>
<h3><a href="#同步" name="同步" class="anchor"><span class="anchor-link"></span></a>同步</h3>
<p>如果有一天，事务内存证明它能为任何人完成任何事情，那么它就不必与其他同步机制进行交互。直到现在为止，它仍然必须与同步机制协调工作，这些同步机制可以做一些它完成不了的工作，或者说在特定情况下能更加自然的工作。下面的章节展示了目前这个领域遇到的挑战。</p>
<h4><a href="#锁" name="锁" class="anchor"><span class="anchor-link"></span></a>锁</h4>
<p>在持有一些锁时，再去获取其他锁，这是很常见的场景，并且也工作的很好，这主要是因为运用了软件工程技术来避免死锁。同时，在 RCU 读端临界区中申请锁也十分常见。RCU 读端原子操作并不具备产生死锁的因素，所以人么使用这种方案是不必过多考虑死锁的可能。但是，当你尝试在事务中申请锁会发生什么？</p>
<p>从原理上讲，答案是简单维护作为事务一部分的锁所用到的数据结构，这会运作的很好。实际上，有大量不明显的复杂因素在里面，这依赖于 TM 系统的实现细节。这些复杂因素可以被解决，但是其代价是在事务之外的锁，增加 45% 的开销，在事务内的锁，增加 300% 的开销。虽然在包含少量锁的事务程序中，这些开销是可以接受的，但是在一些基于所的产品级程序中，如果偶尔想使用事务，这常常是难以接受的。</p>
<ol>
  <li>仅使用锁友好的 TM 实现。不幸的是，非锁友好的 TM 实现有一些吸引人的特性，包括成功事务的低负载，以及提供大型事务的能力。</li>
  <li>在基于锁的程序中，在引入 TM 时，仅仅使用少量 TM，以此来兼容锁友好型 TM 的实现。</li>
  <li>完全撇开基于锁的遗留系统，用事务来重新实现所有东西。这种方法不缺少支持者，但是这需要解决这里所列出的所有问题。由于解决这些问题需要时间，警长同步机制当让也有改进的机会。</li>
  <li>在基于所的系统中，仅仅使用 TM 作为优化手段，TxLinux 组已经这样做了。这种方法听起来很好，但是确实存在锁约束(如需要避免死锁)。</li>
  <li>尽量减少锁机制的负载。</li>
</ol>
<p>TM 和锁之间的交互可能会有一些问题，这对很多人来说是令人惊奇的。在实际的产品级软件里，新机制和新原语的需求越来越强烈。幸运的是，开源的出现使得有大量这样的软禁，对于所有人来说都是可用的，也包括研究者。</p>
<h4><a href="#读者-写者锁" name="读者-写者锁" class="anchor"><span class="anchor-link"></span></a>读者——写者锁</h4>
<p>在持有其他锁的时候，请求锁是很平常的，前提是使用了软件工程技术来避免死锁。在 RCU 读锁保护的临界区内，申请锁也是可以的，并且这样做也不需要过多考虑死锁的可能，因为 RCU 读端原子操作并不具备产生死锁的因素。当时当你在一个事务中申请读锁会发生什么？</p>
<p>不幸的是，直接在事务中使用传统的基于计数的读写锁达不到读写锁的目的。要明白这一点，考虑一对事务并发的尝试申请同一个读锁。由于申请读锁会修改读写锁数据结构，这将会产生冲突，并回退两个事务中的其中一个。这与读写锁允许多个读者的目的完全不符。</p>
<p>以下是 TM 中的一些可用选项：</p>
<ol>
  <li>使用每 CPU 或者每线程的读写锁，这允许特定的 CPU 或线程在申请读锁时仅仅维护局部数据，这将避免两个事务之间在申请锁时产生冲突，从而两个事务都能被处理，这正是我们想要的结果。不幸的是：(1)每 CPU 或线程的写锁代价非常高；(2)每 CPU/线程锁的内存代价本来可能是可以避免的；(3)仅仅当你能够访问源代码时，这种变化才是可行的。最近的可扩展读写锁可以避免这些问题中的一部分或全部。</li>
  <li>在基于所的程序中引入 TM 时，仅仅少量使用 TM，这样可以避免在事务中使用读锁。</li>
  <li>完全撇开基于所的遗留系统。使用事务重新实现所有的东西。这种方法不乏支持者。但是这需要解决这里列出的所有问题。由于解决这些问题需要事件，因此竞争同步机制当然也有改进的机会。</li>
  <li>在基于锁的系统中，仅仅使用 TM 作为优化手段，TxLinux 组已经这样做了。这种方法听起来很好，但是确实存在锁约束。此外，当多个事务同时申请一个锁时，这种方法会产生不必要的回退。</li>
</ol>
<p>当然，组合使用 TM 和读写锁肯能有一些其他不明显的问题，它事实上会将读锁编程排他锁。</p>
<h4><a href="#rcu" name="rcu" class="anchor"><span class="anchor-link"></span></a>RCU</h4>
<p>由于 RCC 主要用于 Linux 内核，因此即使人们认为结合 RCU 和 TM 没有理论工作要做，这也是可以理解得。但是，来自于 Austin Texas 大学的 TxLinux 组别无选择。事实上，他们在 Linux 2.6 内核中应用了 TM。由于内核使用了 RCU，这使得他们必须集成 TM 和 RCU，TM 位于 RCU 之中。不幸的是，虽然文献上声称 RCU 实现的锁已经转换为事务，但是没有说在基于 RCU 的更新中，使用锁(如 dcache_lock)会发生什么问题。</p>
<p>重要提醒，RCU 允许读者和写者并行运行，更准确的说，允许数据在更新的时候，RCU 读者对其进行访问。当然，对于这些 RCU 属性，无论是其性能、扩展性、实时响应，都与 TM 的原子属性相违背。</p>
<p>因此，基于 TM 的更新，应该如何与并发的 RCU 读者交互呢？有如下可能性：</p>
<ol>
  <li>RCU 读者将与之并行的、冲突的 TM 更新操作中止。这是 TxLinux 项目事实上采用的方法。该方法保留了 RCU 的语义，也保留了 RCU 读者的性能、扩展性、实时响应。但不幸的是，它的副作用是不必要的中止了与之冲突的更新操作。在最坏的情况下，一个长长的读者序列会导致所有更新者产生饥饿，理论上，这会导致系统挂起。另外，不是所有的 TM 实现都能提供实现本方法所需的原子性。</li>
  <li>与冲突的 TM 更新端并行运行的 RCU 读者，都从冲突的 RCU 加载操作中获得旧的值(前一个事务中的值)。这保留了 RCU 的语义和性能，也保护了 RCU 更新免受饥饿的影响。但是，并不是所有的 TM 实现，都能够提供及时访问旧值的功能，尤其是这些旧值是被正在快速执行的事务临时更改的。特别是，基于日志的 TM 实现，会在日志中维护旧值(因此能提供优良的 TM 提交性能)，在本方案下，它工作的不是很好。也许 rcu_dereference 原语能够允许 RCU 在大部分 TM 实现中访问旧值，虽然性能可能会是一个问题。尽管如此，还是有些流行的 TM 实现，能够简单有效的通过这种方案与 RCU 结合。</li>
  <li>如果一个 RCU 读者与一个快速运行的事务产生了冲突访问，那么 RCU 访问被延迟，直到冲突的事务被提交或中止。该方法保留了 RCU 的语义，但是降低了 RCU 的性能和实时响应能力，特别是存在长时间运行的事务时。另外，并不是所有的 TM 都有将冲突访问进行延时的能力。即便如此，该方法看起来对仅仅支持小事务的硬件 TM 实现是非常合理的。</li>
  <li>将 RCU 读者转换为事务。该方法可以保证与任何 TM 实现都可以非常好的兼容，但是 RCU 读锁保护的临界区也收到 TM 回退的影响，使得 RCU 失去了实时响应的保证，也降低了 RCU 读端的性能。而且，在 RCU 读端临界区包含 TM 实现锁不能处理的操作时，该方法是不可行的。</li>
  <li>很多地方使用 RCU 写更新修改一个指针，以发布一个新的数据结构。这种情况下，能够安全的允许 RCU 看到这个事务指针，即使随后事务被回退。只要事务遵守内存序，并且回退过程使用 call_rcu 释放对应的数据结构。不幸的是，并不是所有的 TM 实现都在事务中遵守内存序。显然，其想法是由于事务是原子的，因此事务内的内存序并不重要。</li>
  <li>禁止在 RCU 更新端使用 TM。这确保能够正常工作，但是看起来有一些限制。</li>
</ol>
<p>看起来很有可能会有其他方法出现，特别是考虑到用户态 RCU 已经出现。</p>
<h4><a href="#事务外访问" name="事务外访问" class="anchor"><span class="anchor-link"></span></a>事务外访问</h4>
<p>在基于所的临界区中，可以合法的维护那些锁的临界区外并发访问甚至是修改变量，一个常见的例子是统计计数。在 RCU 读端临界区做同样的事情也是合法的，其实人们也经常这样做。</p>
<p>对于像名为“脏读”这样的机制，已经在产品级的数据库系统中广为流行了，请不要感到奇怪，事务外访问已经收到 TM 支持者的认真关注，其中一个关注点是弱、强原子性的概念。</p>
<p>以下是一些在 TM 中可用的事务外访问选项：</p>
<ol>
  <li>事务外访问冲突，总是导致事务被中止。这是强原子性。</li>
  <li>事务外访问冲突被忽略。因此仅仅在事务内的冲突才中止事务。这是弱原子性。</li>
  <li>在特殊情况下，例如，分配内存，或者与基于锁的临界区交互时，事务被允许执行非事务操作。</li>
  <li>扩展硬件以支持多个事务对单个变量并发的执行某些访问。</li>
  <li>向事务内存引入弱语义。一种方法是如 17.2.3.3 节所述，将其与 RCU 组合使用，而 Gramoli 和 Guerraou 调查了一些其他弱事务方法，例如：将大的弹性事务分割成小的事务，从而减少冲突概率(尽管性能和扩展性不好)。也许，更多的经验表明，某些事务外访问的用法，可以被替换为弱事务。</li>
</ol>
<p>事务似乎被设计成一种单独存在的机制，不需要与其他同步机制进行交互。这样的话，当非事务访问和事务访问结合在一起的时候，引起更多的复杂性和混乱就不足为奇了。但是除非限定事务对独立的数据结构进行小的更新，或者限制新程序不与现有的、大的并行代码进行交互，否则，事务要想在短期内产生影响，就必然存在这样的组合。</p>
<h3><a href="#讨论" name="讨论" class="anchor"><span class="anchor-link"></span></a>讨论</h3>
<p>采用通用 TM 的障碍，带来了一下结论：</p>
<ol>
  <li>一个有趣的 TM 特点是事务收到回退及重试的限制。这个特点引出了 TM 不能撤销操作的难题。包括不可缓冲的 IO、RPC、内存映射操作、延时，以及 exec 系统调用。同时，这一属性也有不幸的后果，引入了同步原语所固有的、可能失败的可能性锁带来的所有复杂性，很多是以开发者可见的形式引入的。</li>
  <li>TM 另外一个有趣的特点，由 Shpeisman 注意到，是 TM 与它所保护的数据之间盘根错节的纠缠。这直接引出了 TM 里的 IO、内存映射操作、事务外访问及断点调试等难题。与之相对的是，传统的同步原语，包括所和 RCU，在它们要保护的数据与同步原语之间存在清晰的区分。</li>
  <li>在 TM 领域中，很多工作的既定目标之一是使大的顺序代码段变得易于编程。因而，通常期望独立的事务能够串行运行，这可以解释 TM 在多线程事务方面的问题。</li>
</ol>
<p>关于所有这些问题，TM 研究者和开发者都需要做什么？</p>
<p>一个方法是聚焦于小型 TM，关注与这样的情形，通过硬件的潜在帮助，提供超过其他 同步原语的实质优势。这实际上是 SUN 在它的 Rock 这款研究性 CPU 上采用的方法。一些 TM 研究者看起来接受这个方法，但是其他研究者对 TM 寄予了更高的期望。</p>
<p>当然，TM 将能够解决更大型的问题，这是十分有可能的，但如果要达到这个崇高的目标，本节列出的一些问题必须被解决。</p>
<p>当然，每个参与其中的人都应该视之为一次学习的经历。看上去 TM 研究者已经从成功使用传统同步原语构建器大型软件的工业时间者那里学到了不少东西。</p>
<p>反之亦然。</p>
<p>但是直到目前，STM 的当前状态最好被总结为一系列卡通片。首先，图 17.8 显示了 STM 的样子。和以往一样，实际上还是有那么一点细微的差别，这夸张的表示在了图 17.9、17.10、17.11 中。</p>
<p>商业可用硬件的最新进展，为 HTM 的变体打开了一次机会之窗，这将在后面的章节介绍。</p>
<h2><a href="#硬件事务内存" name="硬件事务内存" class="anchor"><span class="anchor-link"></span></a>硬件事务内存</h2>
<p>截止 2012 年初，硬件事务内存(HTM)开始出现在商业计算机中。本节首先尝试在并行程序工具箱中找到他的位置。</p>
<p>从概念角度来看，HTM 使用处理器高速缓存和预测执行，来使一组指定的语句(事务)生效，并且在其他处理器上运行的事务看来，这些语句是原子性的。这些事务由启动事务机器指令来初始化，然后由提交事务机器指令来完成。通常还有中止事务机器指令，用来撤销预测执行(就像启动事务处理机器码和接下来的指令都没有执行过一样)，并且在错误处理的位置执行。错误处理的地址，通常由开始事务指令来指定，要么是作为一个显式的错误处理地址赋值，或者是被指令本身通过条件码来设置。每个事务对其他事务来说都是原子执行的。</p>
<p>HTM 有许多重要的优势，包括自动动态分区的数据结构，减少同步原语的缓存缺失，并支持相当数量的实际应用。</p>
<p>但是，华丽的外表总是需要代价的，HTM 也不例外。本节的主要论点是，在什么情况下，选择 HTM 是益处大于其外表锁隐藏的弊端。</p>
<h3><a href="#htm-与锁相比的优势" name="htm-与锁相比的优势" class="anchor"><span class="anchor-link"></span></a>HTM 与锁相比的优势</h3>
<p>HTM 的主要优势是：</p>
<ol>
  <li>可以避免其他同步原语通常会产生的缓存缺失。</li>
  <li>它动态划分数据结构的能力。</li>
  <li>它有大量可用的应用程序的事实。</li>
</ol>
<p>我打破 HTM 传统，没有把易用性单独列出是因为有两个原因。首先，易用性是 HTM 的主要优点，本文着重介绍。第二，一直存在相当大的争议，在工作面试中，是否应该测试纯编程能力，甚至是进行一些小型编程练习。这表明，我们真的不知道到底是什么把编程简化还是复杂化了。因此，下面各节终点分析上面列出的三个优势。</p>
<h4><a href="#避免同步带来的缓存缺失" name="避免同步带来的缓存缺失" class="anchor"><span class="anchor-link"></span></a>避免同步带来的缓存缺失</h4>
<p>大多数同步机制，都是基于数据结构的，这些数据结构的操作由原子指令来完成。由于这些原子指令，通常是先诱发他们所在的 CPU 将对应的缓存行占用，其他 CPU 如果要执行这些同步原语的相同实例的话，则会诱发缓存缺失。这些缓存缺失通信会同时严重降低普通同步机制的性能和扩展性。</p>
<p>相反的，HTM 同步靠的是 CPU 缓存，避免了同步数据结构及随之而来的缓存缺失。当我们将锁的数据结构放到不同的缓存行时，HTM 最能体现其优势。这种情况下，将特定临界区转换为一个 HTM 事务，能够为临界区减少一次完整的缓存缺失的开销。对于十分小的临界区来说，这些节省下来的开销十分可观。至少对于这种情况是这样，去掉的锁与受锁保护的反复写的变量之前，不共享相同的缓存行。</p>
<h4><a href="#对数据结构进行动态分区" name="对数据结构进行动态分区" class="anchor"><span class="anchor-link"></span></a>对数据结构进行动态分区</h4>
<p>在使用一些普通的同步机制时，一个主要的障碍就是对数据结构进行静态划分。有很多数据结构是可分区的，最典型的例子就是哈希表，每条哈希冲突链构成一个分区部分。为每条冲突链分配一把锁，然后轻松将哈希表的操作并行化，即只需要操作特定的一条冲突链。对于类似的数组、基树及一些其他数据结构来说，分区也是小菜一碟。</p>
<p>但是将很多类型的树或者图进行分区都很困难，分区的结果也很复杂。虽然可以用两段锁和哈希数组形式的锁来划分通用的数据结构，但其他技术显然已被证明更适合这种情况，我们将在 17.3.3 节讨论。由于避免了同步带来的缓存缺失，因此针对大型的不可分区数据结构来说，HTM 是一个非常可行的措施，因此针对大型的不可分区数据结构来说，HTM 是一个非常可行的措施，至少在更新相对较小的场合如此。</p>
<h4><a href="#实用价值" name="实用价值" class="anchor"><span class="anchor-link"></span></a>实用价值</h4>
<p>HTM 实用价值的一些证据，已经被大量硬件平台所证实，包括 Sun Rock 及 Azul Vega。可以合理的假设，实际好处将来自于更新的 IBM Blue Gene/Q、Intel Haswell TSX 及 AMD AFS 系统。</p>
<p>预期的实际好处包括两点。</p>
<ol>
  <li>内存数据访问和更新将不需要锁。</li>
  <li>对大型不可分区数据结构的并行访问和小规模的随机修改。</li>
</ol>
<p>但是，HTM 也有一些非常现实的缺点，下面将继续介绍。</p>
<h3><a href="#htm-与锁相比的优势" name="htm-与锁相比的优势" class="anchor"><span class="anchor-link"></span></a>HTM 与锁相比的优势</h3>
<p>HTM 的概念很简单，一组内存访问及更新原子的发生。但是，与许多简单的想法一样，当你尝试将它运行到真实世界的真实系统上时，复杂性就会出现。这些复杂性如下：</p>
<ol>
  <li>事务大小限制。</li>
  <li>冲突处理。</li>
  <li>中止和回退。</li>
  <li>缺乏前向执行的保证。</li>
  <li>不可撤销操作。</li>
  <li>语义差异。</li>
</ol>
<p>每一个复杂性都包含在随后的章节中，每一节都跟随着一个概要介绍。</p>
<h4><a href="#事务大小限制" name="事务大小限制" class="anchor"><span class="anchor-link"></span></a>事务大小限制</h4>
<p>当前 HTM 实现的事务大小限制，来源于使用处理器缓存来持有那些受事务影响的数据。虽然这允许一个特定的 CPU，通过在它的缓存范围内执行事务。使得事务对其他 CPU 看起来是原子的，但这也意味着其他不适合的事务必须被中止。此外，一些改变上下文的事件，如中断、系统调用、异常、自陷及进程上下文切换，这些事件要么中止当前 CPU 上正在执行的事务，要么由于其他执行上下文缓存印记的缘故，进一步限制事务的大小。</p>
<p>当然，现代 CPU 往往都拥有较大的缓存，许多事务需要的数据结构很容易填充进 1M 的缓存里。不幸的是，纯粹的尺寸并不重要，问题是大多数缓存可被认为是由硬件实现的哈希表。而且，硬件缓存并不将冲突桶(通常被称为缓存集)连起来，而是给每个集合提供固定数量的缓存行。缓存内每个集合里的元素个数叫做缓存关联度。</p>
<p>虽然缓存关联度是可变的，但在我们正在输入的笔记本上，8 路组相连的 L0 缓存并非罕见。这意味着，如果有一个事务需要跨 9 条缓存行，并且所有的 9 条缓存行空间都映射到同一个集合，那么这个事务不可能完成，额不必理会这个缓存里还有多少 M 额外可用的空间。使得，对于任意一个选定的数据结构里的元素，该元素所在的事件被成功提交的可能性很大，但是不保证一定能够提交。</p>
<p>已经有一些研究工作可以减轻这种限制。全相联的 victim 缓存可以减少关联度的限制，但是对于 victim 缓存大小方面，当前存在严格的性能和能耗限制。也就是说，对于未修改的缓存行，HTM victim 缓存可能很小，因为他们只需要保留地址，数据本身可以写入内存或者被其他缓存做成影子缓存，而地址本身足以检测到一次写冲突。</p>
<p>不受限事务内存(UTM)方案将 DRAM 物理内存作为极大的 vitim 缓存，但是将这样的方案整个进产品级的缓存一致性机制，这仍然是一个未解决的问题。另外，将 DRAM 吴磊内存作为 victim 缓存，但在实际情形里，单个 CPU 能访问的物理内存是固定大小的，这就限制了该 CPU 事务的大小。其他方案将软件和硬件事务内存相结合，人么可以想到，使用 STM 作为一种 HTM 的后备机制。</p>
<p>但是据我所知，当前的可用系统都没有实现上面所说的研究方案，也许是由很好的理由吧。</p>
<h4><a href="#冲突处理" name="冲突处理" class="anchor"><span class="anchor-link"></span></a>冲突处理</h4>
<p>第一个复杂性是冲突的可能性。比如，假设事务 A 和 B 分别定义如下：</p>
<table>
  <thead>
    <tr>
      <th>Transcation A </th>
      <th>Transcation B </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x = 1;<br />y = 3; </td>
      <td>y = 2;<br />x = 4; </td>
    </tr>
  </tbody>
</table>
<p>假设每个事务都在自己的处理器上并发的执行。如果有这种场景，事务 A 在将 x 赋值的同时事务 B 也给 y 赋值，两个事务都不会推进。要明白这一点，假设事务 A 给 y 赋值。于是事务 A 将会和事务 B 交叉存储，违反了事务间原子存储的规则。同理，允许事务 B 给 x 赋值也会破坏原子性规则。这种情况就定义为一个冲突，此时两个并行的事务尝试访问统一个变量，并且至少有一个事务准备给变量赋值。系统于是需要中止其中一个或两个事务，以便继续运行。准确选择被中止的事务，这是一个有趣的主题。在这个主题方面，很可能在未来一段时间持续产出 PhD 论文，参见例子。 对本节的目标而言，我们假设系统选择任意一个事务并将其中止。</p>
<p>另外一个复杂性是冲突检测，这相对比较直接，至少在最简单的情况来看是这样。当一个处理器执行一个事务时，它将每条该事务曾用到的缓存行都标记为属于该事务。如果该处理收到一个请求，该请求包含一个缓存行，而该请求行因为被当前事务使用过而被标记，则一个潜在的冲突发生。更复杂的系统会让当前处理器的事务排序在提出请求的处理器上的事务之前，对这种处理的优化也很可能在一段时间内产出大量的 PhD 论文。但是本节仅讨论一个非常简单的冲突检测策略。</p>
<p>但是，为了让 HTM 有效运行，冲突的可能性必须被降低到足够低的程度。也就要求有效组织数据结构以保持足够低的冲突概率。比如，一个有简单插入、删除、查找操作的红黑树，可以达到这个要求，但是保持一定元素的红黑树则不满足以上要求。另外一个例子，在单个事务中枚举所有元素的红黑树，很可能产生冲突，从而降低性能和扩展性。结果，许多串行程序需要重构才能保证 HTM 有效运行。某些情况下，开发者更乐意采取额外的行动，只使用锁来完成功能(在红黑树的例子里，也许是切换到可分区的数据结构如基树或哈希表)，特别是在 HTM 在所有相关架构里都可用之前。</p>
<p>此外，冲突可能发生的事实也将故障处理带入了我们的视线。</p>
<h4><a href="#终止和回退" name="终止和回退" class="anchor"><span class="anchor-link"></span></a>终止和回退</h4>
<p>因为所有的事务都能在任意时刻中止，因此事务内不包含不可回退的语句是很重要的。这意味着事务内不能有 IO、系统调用、调试端点。相反，事务必须限制自身功能，仅访问正常的、经过缓存的内存。另外，在某些系统里，中断、异常、自陷、TLB 缺失及其他一些事件同样会中止事务。考虑到由于错误条件的不当处理带来的大量 BUG，可以合理的问问，那些影响中止和回退的因素，给易用性带来了影响？</p>
<p>当然，中止和回退带来了一个问题，那就是 HTM 能否被用在硬实时系统中。HTM 带来的性能提升是否大于其中止和回退的开销，如果是的话，又是在什么条件下？或者说，高优先级的事务应该优先中止那些低优先级的事务吗？如果是的话，应该如何通知其优先级？关于 HTM 实时应用的文献相当少，也许是研究者遇到了很多问题，即使在非实时的环境中也不能很好运行。</p>
<p>因为当前 HTM 的实现可能中止其中一个事务，软件必须提供回退代码。回退代码必须使用其他某些形式的同步机制，比如锁。如果回退比较频繁，则锁的限制、死锁的可能性就会出现。当然人们期望回退不会太频繁，这样就可以用比较简单和不易造成死锁的锁设计方案了。但这带来一个问题，使用基于锁的回退机制的系统事务，应该如何回退到事务。一种方法是用“多次检查——设置”规则，这样每个线程都会一直等待直到锁被释放，从而使系统从一个干净的状态启动事务。但是，这也可能带来一定数量的自旋，尤其是锁持有者阻塞或被抢占时，这不是明智的做法。另外一个方案允许事务和锁持有者并行运行，但是这又引起维持原子性的困难，尤其当原因是持有锁的线程是因为对应的事务不能适应缓存时。</p>
<p>最后，处理中止和回退的可能性将对开发者带来额外的负担，开发者必须正确处理所有错误条件的组合。</p>
<p>很明显 HTM 的使用者必须做出足够多的验证努力，来测试回退代码路径，以及测试回退代码回到事务代码的事务路径。</p>
<h4><a href="#缺乏前向执行的保证" name="缺乏前向执行的保证" class="anchor"><span class="anchor-link"></span></a>缺乏前向执行的保证</h4>
<p>即使事务大小、冲突、终止/回退可能导致事务中止，人们还是期望足够小和执行短的事务能够最终保证成功运行。这将允许一个事务能够无条件的重试，与 CAS 和链接加载/条件存储(LL/SC)操作一样，无条件重试来实现原子操作。</p>
<p>不幸的是，最近可用的 HTM 实现，不能提供任何前向执行保证，也就意味着在这些系统中，HTM 不能避免死锁。期望未来 HTM 的实现，能够提供一些前向执行的保证。在此之前，HTM 都必须子啊实时程序中谨慎使用。</p>
<p>2013 年黯淡前景的一个例外，是即将出现的 IBM 大型机，它提供了一个单独的指令，这个指令可用于启动一个特殊的“约束事务”。正如其名，这样的事务必须遵守以下约束：</p>
<ol>
  <li>每个事务的数据印记必须包含在 4 个 32 字节的内存块中。</li>
  <li>每个事务被允许执行最多 32 条汇编指令。</li>
  <li>不允许事务拥有后向分支(如循环)。</li>
  <li>每个事务的代码被限制在 256 字节内存。</li>
  <li>如果一个特定事务的数据印记的一部分位于一个特定 4K 页面之内，那么该 4K 页面禁止包含其他事务的指令。</li>
</ol>
<p>这些约束是重量级的，但是仍然能够允许不同类型的数据结构更新操作被实现，包括堆栈、队列、哈希表等。这些操作被保证最终能够完成，并且没有死锁、活锁条件。</p>
<p>看看硬件是如果随着时间推移来解决前向保证问题的，这很有意思。</p>
<h4><a href="#不可撤销操作" name="不可撤销操作" class="anchor"><span class="anchor-link"></span></a>不可撤销操作</h4>
<p>中止和回退的另外一个后果是，HTM 事务不可能包含不可撤销操作。在当前 HTM 实现中，通常通过如下方式来强制满足这些约束：事务中的所有访问都在可缓存的内存中(因而禁止 MMIO 访问)，以及在中断、自陷和异常时中止事务(因而禁止系统调用)。</p>
<p>请注意，只要缓冲填充/刷新操作在事务外，那么缓冲 IO 就能够由 HTM 处理。可行的原因是：往缓冲加数据和删除数据是可以撤销的。只有实际的缓冲填充/刷新操作才是不可撤销的。当然，这种 IO 缓冲方法带来了一些后果，包括事务中 IO 内存印记、增加事务长度，因而也增加了失败的可能性。</p>
<h4><a href="#语义差异" name="语义差异" class="anchor"><span class="anchor-link"></span></a>语义差异</h4>
<p>虽然 HTM 在很多情况下被作为一种替代锁的选择(即事务锁)，但是存在一些语义方面的细微差别。一个特殊讨厌的例子由 Blundel 给出，即当并行执行事务时，一个互相协调的、基于所的临界区导致死锁或活锁。一个更简单的例子是空临界区。</p>
<p>在一个基于锁的程序中，一个空的临界区保证所有曾经持有锁的进程释放该锁。该方案在 2.4 内核的协议栈里用来协调配置的改变。如果这个空临界区被改为事务，其结果是空操作。当前临界区之前的临界区已经结束，这样的保证将不再存在。换句话说，事务锁保留了锁在数据结构保护方面的语义，但是失去了锁机制的基于时间消息的语义。</p>
<p>锁和事务之间一个重要的语义差别是，在基于锁的实时程序里，采用了优先级提升的方法来避免优先级反转。一种触发优先级反转的场景是，一个持有锁的优先级线程，被一个中优先级、耗 CPU 资源的线程抢占。如果每个 CPU 至少有一个这样的中优先级线程，低优先级线程将永远得不到调度。如果有个高优先级的线程想要获得锁，将被阻塞。直到低优先级线程释放锁之后，它才能获得锁，低优先级线程如果得不到调度就无法释放锁，只有任意一个中优先级的线程释放 CPU 才会让低优先级的线程得到调度。因此，中优先级线程看上去阻塞了高优先级线程，这也就是“优先级反转”这个名称的由来。</p>
<p>一种避免优先级反转的方法是优先级继承。当一个高优先级线程被一把锁阻塞时，将它的优先级传递给锁持有者，这也被称为优先级提升。但是，除了用于避免优先级反转之外，优先级提升还可以用于其他方面。如图 17.12 所示。第 1~12 行表示的是一个低优先级的线程需要 1ms 运行一次，第 14~24 行表示的是一个高优先级的线程用优先级提升策略来保证 boostee 函数根据所需的定期运行。</p>
<div  align="center">
<img src="https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180922205159.png
" style="display:block;width:100%;" alt="NAME" align=center />
</div>
<p>bootstee 函数通过总是持有两个 boost_lock[] 锁中的其中一个的办法来实现这一点。这样第 20~21 行的 booster 函数在必要的情况下就能执行优先级提升。</p>
<p>这种方案要求 boostee 函数在系统边忙之前，通过第 5 行先获取到一把锁，即使在现代硬件上也要求这样做。</p>
<p>但是，当忽略空事务锁的存在时，这种方案就行不通了。boostee 函数的临界区会称为一个无限长的事务，可能会或早或晚的中止。比如，线程第一次执行 boostee 函数时就被抢占。这样一来 boostee 会回退到锁，但是由于它的优先级低，以及初始化周期已经结束(最终 boostee 被抢占)的原因，这个线程将永远没有机会得到运行。</p>
<p>并且，如果 boostee 线程没有获得锁，那么 booster 线程在 20~21 行的空临界区就变成一个空事务，这样它就不会产生效果，于是 boostee 永远不会运行。这个例子演示了内存的回退——重试语义方面的一些微秒效果。</p>
<p>经验很可能会发现一些额外的、微秒的语义差别，基于 HTM 锁机制的大型程序需要小心编写。</p>
<h4><a href="#总结" name="总结" class="anchor"><span class="anchor-link"></span></a>总结</h4>
<p>尽管看起来 HTM 有引入注目的地方，当前的实现由严重的类似于事务大小限制、冲突处理的复杂度、中止——回退问题、需要小心处理语义差别等问题。HTM 与锁的当前状态归纳如下。正如所见，虽然 HTM 的当前状态缓解了锁的很多严重缺点，但它是通过引入了大量缺点来实现的。这些缺点已经被 TM 社区的领导所认可。</p>
<div  align="center">
<img src="https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180922205337.png" style="display:block;width:70%;" alt="NAME" align=center />
</div>
<div  align="center">
<img src="https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180922205312.png" style="display:block;width:70%;" alt="NAME" align=center />
</div>
<p>另外，这还不是故事的全部。所本身并不单独使用，通常是和其他同步机制配合使用，如引用计数、原子计数、非阻塞数据结构、冒险指针、RCU。下节来观察这些增强措施对事情有何改变。</p>
<h3><a href="#htm-与增强后的所机制相比的优势" name="htm-与增强后的所机制相比的优势" class="anchor"><span class="anchor-link"></span></a>HTM 与增强后的所机制相比的优势</h3>
<p>业界长期以来已经使用引用计数、原子计数、非阻塞数据结构、冒险指针、RCU 来避免锁的缺点。比如，通过引用计数、冒险指针、RCU 来保护数据结构，特别是只读临界区，很多情况下可以避免死锁。这些方案也减少了分区数据结构的要求。RCU 更进一步提供了无竞争无等待的读原语。将这些优势添加到上节的表中，得到更新后的锁与 HTM 的对比，见下表。两表的主要差别如下：</p>
<ol>
  <li>采用非阻塞的读机制可以减轻死锁问题。</li>
  <li>冒险指针和 RCU 这样的读机制可以在不分区数据结构上有效运行</li>
  <li>冒险指针和 RCU 不会互相竞争，也不会和写者竞争，因此对于只读区的操作，在性能和扩展性方面，也是极好的。</li>
  <li>冒险指针和 RCU 提供前向执行保证(他们也是无锁、无等待的)。</li>
  <li>冒险指针和 RCU 的内部操作很快。</li>
</ol>
<h3><a href="#htm-最适合的场合" name="htm-最适合的场合" class="anchor"><span class="anchor-link"></span></a>HTM 最适合的场合</h3>
<p>HTM 最适合的地方，看起来是一些有着频繁读写操作的工作负载，这些负载设计那些大型多处理器系统上的大型内存数据结构，其修改操作针对其上的小段区域。因为这样正好满足了当前 HTM 实现里对长度的限制，同时又将其冲突尽可能最小化，也将随之代码的终止回退最小化。这个场景其实对当前的其他同步机制来说也是比较难处理的。</p>
<p>将锁与 HTM 配合使用，看起来可能会克服 HTM 不可撤销操作的困难，而 RCU 或危险指针的使用减轻了 HTM 对于只读区间长度的限制，而这种只读区间一般都针对大型数据结果区间。当前 HTM 实心无条件终止一个与 RCU、冒险指针读冲突的事务，不过也许未来 HTM 的实现会与上述同步机制结合的更加自然。同时，写操作与一个大型 RCU 或冒险指针读临界区冲突的可能性，将远小于与一个只读事务的冲突可能性。而且，一组源源不断的 RCU、冒险指针读者将可能使写者饥饿，因为读者与写者之间有一系列的冲突。通过在事务之前，对要加载的内存位置进行额外的读取，能够避免该漏洞(也许存在显著的硬件成本和复杂性)。</p>
<p>HTM 事务在某些情况必须回退的事实，使得 HTM 需要考虑数据结构的静态划分。如果未来的 HTM 实现能够提供前向执行保证，那么这个限制就能解除，某些情况下也就不需要回退代码了，这样一来，HTM 就能在高冲突环境下有效发挥作用。</p>
<p>长话短说，虽然 HTM 很可能有重要的用途和应用，但它不过是并行编程人员工具箱中的另一个工具，而不能替代整个工具箱。</p>
<h3><a href="#潜在的搅局者" name="潜在的搅局者" class="anchor"><span class="anchor-link"></span></a>潜在的搅局者</h3>
<p>搅局者需要大大提升如下 HTM 需求：</p>
<ol>
  <li>前向执行保证。</li>
  <li>增加事务大小。</li>
  <li>调试功能改进。</li>
  <li>弱原子性。</li>
</ol>
<h4><a href="#前向执行保证" name="前向执行保证" class="anchor"><span class="anchor-link"></span></a>前向执行保证</h4>
<p>如前所述，当前 HTM 的实现缺乏前向执行保证，因此需要可用的软件回退来处理 HTM 的失败。在 HTM 中，前向执行的障碍主要包括：缓存大小和相关性、TLB 大小和相关性、事务时长、中断频率、调试器实现。</p>
<p>前面已经讨论过缓存大小和关联性，以及一些视图解决当前限制问题的研究。但是，HTM 的前向习性保证解决办法，随之而来的事务大限制，虽然在未来大小限制会解决，但是目前还不行。所以，为什么不让当前 HTM 的实现通过小的事务来实现前向执行保证，比如，将其限制到缓存相关性？一个潜在的问题，可能是因为需要处理硬件错误。比如，可以通过停用故障单元的方式，来处理发生故障的缓存 SRAM 单元，这会减少缓存相关性，因而也相应减少了保证前向执行的事务最大长度。鉴于这只会简单的降低前向执行保证的事务长度，似乎是其他原因在起作用。如果人们被告知在软件上实现前向执行保证是相当困难的，那么也许在产品级硬件上提供前向执行保证会比人们想象的更困难。毕竟将一个软件问题通过硬件来解决更不容易。</p>
<p>对于一个屋里地址标记、物理地址索引的缓存，仅仅将事务放到内存里还是不够的。其地址转换也必须适合 TLB。于是任何前向保证机制必须考虑 TLB 大小和关联度影响。</p>
<p>对于当前 HTM 实现中的中断、自陷、异常会中止事务的事实，特定事务执行时间小于预期中断间隔，这是必须的。不管一个特定事务关联的数量有多小，如果它执行时间太长，也会被中止。因此，任何前向执行保证不但保证必须以事务大小为前提条件，也必须以执行周期为前提条件。</p>
<p>前向执行保证机制严重依赖于某种仲裁机制，即决定到底是中止哪个事务。人们很容易想到这种场景，假设又有个无止境的事务序列，每一个都仅仅中止前一个事务，它自己又仅仅被后面事务中止，这样没有一个事务会被提交。冲突处理的复杂性已经被大量曾经提出的 HTM 冲突解决策略锁证明。事务外访问带来了更多的复杂度，如 Blundell 所描述。很容易就把这种复杂性归罪于事务外访问，但是通过把每个事务外访问改为单事务内访问，人们会发现这种归罪是没有道理的。问题的根源在于访问的方式，而不在于它们是否位于事务内。</p>
<p>最后，事务的前向执行保证也依赖于调度器，后者必须保证作为事务载体的线程得到足够的时间来运行。</p>
<p>因此，对于 HTM 供应商来说，要提供前向执行保证有相当大的困难。但是，任何解决该问题的措施都会影响巨大。那将意味着，HTM 事务不再需要软件回退，也就意味着 HTM 最终将实现 HTM 锁承诺的死锁解除。</p>
<p>截止 2012 年底，IBM 大型机宣布了一个 HTM 实现，它包含了通常尽力而为的 HTM 实现之外的约束事务。约束事务开始于 tbeginc 指令而不是 tbegin 指令，该指令用于尽力而为的事务。约束事务被保证总是会完成(最终完成)，因此如果事务被中止了，硬件不是转向回退路径(这是尽力而为事务所做的)，而是启动位于 tbeginc 指令的事务。</p>
<p>大型机架构需要采用严格的措施来实现这种前向执行保证。如果一个特定约束事务反复失败，CPU 就可能会禁止分支预测，强制按序执行，甚至禁止流水线。如果反复失败是因为冲突太多导致，那么 CPU 可能禁用推测预取，引入随机延迟，甚至将冲突 CPU 串行执行。“有趣的”前向执行情形涉及至少两个，多达上百个 CPU。这些极端的措施也许提供了一个视角，来考察为什么其他 CPU 至今仍然避免提供约束事务。</p>
<p>顾名思义，约束事务实际上受到严格约束：</p>
<ol>
  <li>最大数据印记是 4 块内存，每块不超过 32 字节。</li>
  <li>最大的代码印记是 256 字节。</li>
  <li>如果一个特定的 4K 页面包含一个约束事务代码，那么该页面不能包含该事务的数据。</li>
  <li>可被执行的最大汇编指令数量是 32。</li>
  <li>后向分支是被禁止的。</li>
</ol>
<p>然而，这些约束支持大量数据结构，包括链表、堆栈、队列及数组。因此约束事务看起来极有可能成为并行开发工具箱中的重要工具。</p>
<h4><a href="#增加事务大小" name="增加事务大小" class="anchor"><span class="anchor-link"></span></a>增加事务大小</h4>
<p>前向执行保证很重要，但正如我们所见，事务大小和时长是前向执行的基础。很重要的一点是，就算是尺寸很小的前向保证，也很有用。比如，两个缓存行长度的保证对栈、入队或者出队是足够的。但是，更大的数据结构需要更大的保证，比如，按序遍历一棵树需要对树节点个数的保证。</p>
<p>因此，增加长度的保证也增加了 HTM 的用途，因而要求 CPU 要么提供该功能，要么提供足够好的变通方案。</p>
<h4><a href="#改进调试支持" name="改进调试支持" class="anchor"><span class="anchor-link"></span></a>改进调试支持</h4>
<p>影响事务尺寸的另外一个因素是调试事务的需求。当前实现的问题是，单步异常会中止所属的事务。该该问题由大量的变通方案，包括模拟处理器(慢)，用 STM 来替换 HTM(慢且语义有差别)，采用重复尝试来模拟前向执行的回放技术(奇怪的错误模型)，调试 HTM 的全面支持(复杂)。</p>
<p>如果一个 HTM 生产商提供一个 HTM 系统，这种系统允许在事务中直接使用经典的调试技术，包括断点、单步、但因语句，这将使 HTM 更有吸引力。一些事务内存研究者在 2013 年开始注意这个问题，至少有一个设计硬件相关调试手段的建议。当然，这个建议依赖于容易获得可用的硬件。</p>
<h4><a href="#弱原子性" name="弱原子性" class="anchor"><span class="anchor-link"></span></a>弱原子性</h4>
<p>既然 HTM 在可预见的未来很可能会遇到一些尺寸的限制，因此 HTM 很有必要与其他几只无缝结合。如果事务外的读取，不会无条件中止与其写冲突的事务，相反，读操作简单的由事务前的值所提供，那么将会改进 HTM 与类似于冒险指针和 RCU 这样的只读几只的互操作性。以这种方式，冒险指针和 RCU 能被用于允许 HTM 处理更大的数据结构以减少冲突概率。</p>
<p>然而并不是如此简单。最直接的实现方式是需要在每条缓存行和总线上添加一个额外的状态，这个额外的代建还是很客观的。增加这个代价带来的好处是允许大内存印记的读者，而产生写者饿死的风险，这些风险是由连续冲突产生的。</p>
<h3><a href="#结论" name="结论" class="anchor"><span class="anchor-link"></span></a>结论</h3>
<p>虽然当前 HTM 实现看起来准备提供实在的好处，但是也有其显著的缺点。最显著的缺点是事务大小受限，冲突处理的要求，中止及回退的要求，缺乏前向保证，不允许处理不可撤销的操作，与锁之间的微秒语义差别。</p>
<p>其中一些缺点可能会在未来的实现中减轻，但是看起来仍然强烈需要使用 HTM 与其他很多类型的同步一致一起配合使用，正如较早前所述那样。</p>
<p>简而言之，当前 HTM 实现看起来是并行开发工具箱中受欢迎的、有用的补充，并且很多有趣的、有挑战性的工作需要使用它们。但是，它们不能被认为就是魔术棒——能解决所有并行编程问题。</p>
<h2><a href="#并行函数式编程" name="并行函数式编程" class="anchor"><span class="anchor-link"></span></a>并行函数式编程</h2>
<p>当我在 20 世纪 80 年代初期开始第一个函数式编程课时，教授声称无副作用的函数式编程风格非常适合琐碎的并行化和分析。三年过去了，这个说法仍然存在，但是使用并行函数语言的主流产品很少，可能是来自教授的其他说法导致的，程序既不维护状态也不应当进行 IO。有一些函数式语言的良好运用，例如 Erlang，并且多线程支持已经被加入到几种其他函数式语言，但是主流产品用法依然继续提供过程语言，如 C、C++、Java 和 Fortan(通常与 OpenMP、MPI 一起增强，或者在 Fortan 情况下，与 coarray 进行增强)。</p>
<p>这种情况很自然就带来了如下问题，如果分析是目标，那么在进行分析之前，为什么不讲过程语言转换为函数式语言？当然有一些反对这个方法的声音，在此列出 3 个。</p>
<ol>
  <li>过程语言通常大量使用全局变量，可以被不同函数单独的修改，或者更糟的是被多个线程修改。注意 Haskell 的 monads 意图处理单线程化的全局状态，对于多线程化的全局状态访问，需要对函数式模式进行额外的暴力处理。</li>
  <li>多线程化的过程语言通常使用像锁、原子操作、事务这样的同步原语，这要求函数式模式增加更多的暴力处理。</li>
  <li>过程语言可以将函数参数化别名，例如，通过两个不同参数将指向相同数据指针传到特定函数的同一个调用。这可能导致函数不知不觉间通过两个不同的代码序列(并且有可能重叠)修改数据结构，这极大地增加了分析难度。</li>
</ol>
<p>另一种方法是将并行过程语言编译为函数式程序，使用函数式程序工具来分析其结果。但是有可能做得比他更好，因为任何真实的计算是一个大的有限状态机，它有有限的输入，并且运行一段有限的时间周期。这意味着任何真实的程序可以被转换为一个表达式，该表达式会大的不切合实际。</p>
<p>但是，将大量并行算法的底层核心转换为表达式，会小刀足以轻易的将其放入现代计算机内存。如果这样的表达式与断言进行组合，检查断言是否发生，就变成了可满足性问题。即使可满足性问题是 NP 完全的，与生成完整状态空间的需求相比，他们通常可以在更少的时间内被解决。另外，求解时间似乎与底层内存模型无关，因此运行在弱序系统上的算法可以像运行在顺序一致性系统中那样快速检查。</p>
<p>一个可能反对的声音是，它不能优雅的处理循环结构。但是，在很多情况下，这可能将循环展开一定次数来解决。而且，可以证明，某些循环能够通过归纳的方法被消除。</p>
<p>另一个可能反对的声音是，自旋锁包含任意长度的循环，任何有限次数的展开将不能捕获自旋锁的完整行为。事实证明这个反对声音可以被很容易的说服。与模仿完整的自旋锁不同，模仿试图获得一个锁的 trylock，但是在它不能立即获得的时候中止它。必须小心设置断言，在自旋锁由于不能立即获得而中止的情况下，避免触发锁。由于逻辑表达式是独立于时间的，于是所有可能的行为将通过这种方式被捕获。</p>
<p>最后一种反对的声音是，这种技术不太可能用于处理大尺寸的软件，如构成 Linux 内核的数百网行代码。这种情况是确实存在的，但事实是，对每一个小的多的并行原语进行详尽验证，是非常有价值的。实际上研究者已经带头将这种方法应用到非实验性质的真实代码中，包括 Linux 内核中的 RCU 实现(尽管 RCU 是一个不太重要的属性)。</p>
<p>这种技术仍然被大范围的应用，但它是形式验证领域更有意思的革新之一，并且它比用函数式形式编写所有程序的传统建议更易被接受。</p>
<div class="nav-next">
<p><strong>Next:</strong> <a href="../../high-performance/ipph/c-mem-barrier.html">C-内存屏障</a></p>
</div>
</div>
<div class="large-3 show-for-large column" data-sticky-container>
<nav class="sidebar sticky" data-sticky data-anchor="docs" data-sticky-on="large">
<div class="page-nav">
<div class="nav-title">On this page:</div>
<div class="nav-toc">
<ul>
  <li><a href="../../high-performance/ipph/ch17-future-confilict.html#ch17-未来的冲突" class="header">CH17-未来的冲突</a>
  <ul>
    <li><a href="../../high-performance/ipph/ch17-future-confilict.html#曾经的-cpu-技术不代表未来" class="header">曾经的 CPU 技术不代表未来</a></li>
    <li><a href="../../high-performance/ipph/ch17-future-confilict.html#事务内存" class="header">事务内存</a></li>
    <li><a href="../../high-performance/ipph/ch17-future-confilict.html#硬件事务内存" class="header">硬件事务内存</a></li>
    <li><a href="../../high-performance/ipph/ch17-future-confilict.html#并行函数式编程" class="header">并行函数式编程</a></li>
  </ul></li>
</ul>
</div>
</div>
</nav>
</div>
</div>

</section>
</div>

</div>

<footer class="site-footer">

<section class="site-footer-nav">
<div class="expanded row">
<div class="small-12 large-offset-2 large-10 column">
<div class="row site-footer-content">

<div class="small-12 medium-4 large-3 text-center column">
<div class="nav-links">
<ul>
<!-- <li><a href="https://www.example.com/products/">Products</a> -->
</ul>
</div>
</div>

</div>
</div>
</div>
</section>

<section class="site-footer-base">
<div class="expanded row">
<div class="small-12 large-offset-2 large-10 column">
<div class="row site-footer-content">

<div class="small-12 text-center large-9 column">

<!--
<div class="copyright">
<span class="text">&copy; 2018</span>
<a href="https://www.example.com" class="logo">logo</a>
</div>
-->
</div>

</div>
</div>
</div>
</section>
</footer>

</div>
</div>
</div>
</body>

<script type="text/javascript" src="../../lib/foundation/dist/foundation.min.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="../../js/magellan.js"></script>

<style type="text/css">@import "../../lib/prettify/prettify.css";</style>
<script type="text/javascript" src="../../lib/prettify/prettify.js"></script>
<script type="text/javascript" src="../../lib/prettify/lang-scala.js"></script>
<script type="text/javascript">jQuery(function(){window.prettyPrint && prettyPrint()});</script>
<script type="text/javascript">jQuery(function(jq){initOldVersionWarnings(jq, '1.0', '')});</script>


</html>
